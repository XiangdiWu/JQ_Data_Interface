# JQData é¡¹ç›®ä¼˜åŒ–å»ºè®®æ–‡æ¡£

## ğŸ“‹ æ¦‚è¿°

æœ¬æ–‡æ¡£åŸºäºå¯¹ JQData é¡¹ç›®çš„æ·±å…¥åˆ†æï¼Œæä¾›å…¨é¢çš„ä¼˜åŒ–å»ºè®®ï¼Œæ¶µç›–ä»£ç è´¨é‡ã€æ€§èƒ½ä¼˜åŒ–ã€æ¶æ„è®¾è®¡ã€æ•°æ®ç®¡ç†ç­‰å¤šä¸ªç»´åº¦ï¼Œæ—¨åœ¨æå‡é¡¹ç›®çš„å¯ç»´æŠ¤æ€§ã€æ‰©å±•æ€§å’Œæ‰§è¡Œæ•ˆç‡ã€‚

## ğŸ¯ ä¼˜åŒ–ç›®æ ‡

- **æå‡ä»£ç è´¨é‡**: å¢å¼ºä»£ç å¯è¯»æ€§ã€å¯ç»´æŠ¤æ€§å’Œå¤ç”¨æ€§
- **ä¼˜åŒ–æ€§èƒ½**: å‡å°‘APIè°ƒç”¨æ¬¡æ•°ï¼Œæé«˜æ•°æ®è·å–æ•ˆç‡
- **å®Œå–„æ¶æ„**: å»ºç«‹æ¸…æ™°çš„æ¨¡å—åŒ–æ¶æ„
- **å¢å¼ºå¥å£®æ€§**: æ”¹è¿›é”™è¯¯å¤„ç†å’Œå¼‚å¸¸æ¢å¤æœºåˆ¶
- **æ‰©å±•åŠŸèƒ½**: æ·»åŠ æ›´å¤šå®ç”¨åŠŸèƒ½å’Œæ•°æ®åˆ†æèƒ½åŠ›

---

## ğŸ”§ ä»£ç è´¨é‡ä¼˜åŒ–

### 1. ç»Ÿä¸€ä»£ç é£æ ¼

**å½“å‰é—®é¢˜**:
- ä»£ç é£æ ¼ä¸ä¸€è‡´ï¼ˆç¼©è¿›ã€ç©ºæ ¼ã€å‘½åè§„èŒƒï¼‰
- ç¼ºå°‘ç±»å‹æ³¨è§£
- å‡½æ•°æ–‡æ¡£å­—ç¬¦ä¸²ä¸å®Œæ•´

**ä¼˜åŒ–å»ºè®®**:

```python
# å»ºè®®çš„ä»£ç é£æ ¼ç¤ºä¾‹
from typing import List, Optional, Dict, Any
import pandas as pd
import os
from datetime import datetime, date

def get_stock_price_data(
    stock_codes: List[str], 
    start_date: str, 
    end_date: str,
    fields: Optional[List[str]] = None
) -> pd.DataFrame:
    """
    è·å–è‚¡ç¥¨ä»·æ ¼æ•°æ®
    
    Args:
        stock_codes: è‚¡ç¥¨ä»£ç åˆ—è¡¨
        start_date: å¼€å§‹æ—¥æœŸï¼Œæ ¼å¼ 'YYYY-MM-DD'
        end_date: ç»“æŸæ—¥æœŸï¼Œæ ¼å¼ 'YYYY-MM-DD'
        fields: è¦è·å–çš„å­—æ®µåˆ—è¡¨ï¼Œé»˜è®¤ä¸ºNoneè·å–æ‰€æœ‰å­—æ®µ
        
    Returns:
        pd.DataFrame: è‚¡ç¥¨ä»·æ ¼æ•°æ®
        
    Raises:
        ValueError: æ—¥æœŸæ ¼å¼é”™è¯¯æˆ–è‚¡ç¥¨ä»£ç ä¸ºç©º
        ConnectionError: APIè¿æ¥å¤±è´¥
    """
    if not stock_codes:
        raise ValueError("è‚¡ç¥¨ä»£ç åˆ—è¡¨ä¸èƒ½ä¸ºç©º")
    
    # å®ç°ä»£ç ...
```

### 2. å»ºç«‹é…ç½®ç®¡ç†ç±»

**å½“å‰é—®é¢˜**:
- é…ç½®åˆ†æ•£åœ¨å¤šä¸ªæ–‡ä»¶ä¸­
- ç¡¬ç¼–ç çš„é…ç½®å€¼
- ç¼ºå°‘ç¯å¢ƒé…ç½®æ”¯æŒ

**ä¼˜åŒ–å»ºè®®**:

```python
# config/settings.py
from dataclasses import dataclass
from typing import Optional
import os

@dataclass
class JQConfig:
    """JoinQuanté…ç½®ç±»"""
    username: str
    password: str
    start_date: str = '2024-01-01'
    end_date: str = None
    max_retries: int = 3
    timeout: int = 30
    
    @classmethod
    def from_env(cls) -> 'JQConfig':
        """ä»ç¯å¢ƒå˜é‡åŠ è½½é…ç½®"""
        return cls(
            username=os.getenv('JQ_USERNAME', ''),
            password=os.getenv('JQ_PASSWORD', ''),
            start_date=os.getenv('JQ_START_DATE', '2024-01-01'),
            end_date=os.getenv('JQ_END_DATE'),
        )

@dataclass
class DatabaseConfig:
    """æ•°æ®åº“é…ç½®ç±»"""
    base_path: str = 'Database'
    encoding: str = 'utf-8-sig'
    backup_enabled: bool = True
    backup_path: str = 'Database/backup'
```

### 3. åˆ›å»ºæ•°æ®æ¨¡å‹ç±»

**ä¼˜åŒ–å»ºè®®**:

```python
# models/data_models.py
from dataclasses import dataclass
from datetime import datetime
from typing import Optional

@dataclass
class StockPrice:
    """è‚¡ç¥¨ä»·æ ¼æ•°æ®æ¨¡å‹"""
    code: str
    date: datetime
    open: float
    high: float
    low: float
    close: float
    volume: int
    amount: float

@dataclass
class FinancialData:
    """è´¢åŠ¡æ•°æ®æ¨¡å‹"""
    code: str
    report_date: datetime
    pub_date: datetime
    report_type: int
    data: dict
```

---

## ğŸš€ æ€§èƒ½ä¼˜åŒ–

### 1. APIè°ƒç”¨ä¼˜åŒ–

**å½“å‰é—®é¢˜**:
- é¢‘ç¹çš„å•è‚¡APIè°ƒç”¨
- ç¼ºå°‘æ‰¹é‡å¤„ç†æœºåˆ¶
- æ²¡æœ‰è¯·æ±‚ç¼“å­˜

**ä¼˜åŒ–å»ºè®®**:

```python
# core/api_client.py
import time
from typing import List, Dict, Any
from functools import lru_cache
import jqdatasdk

class RateLimiter:
    """APIè°ƒç”¨é¢‘ç‡é™åˆ¶å™¨"""
    def __init__(self, max_calls: int = 100, time_window: int = 60):
        self.max_calls = max_calls
        self.time_window = time_window
        self.calls = []
    
    def wait_if_needed(self):
        """å¦‚æœéœ€è¦ï¼Œç­‰å¾…åˆ°å¯ä»¥å‘èµ·ä¸‹ä¸€æ¬¡è°ƒç”¨"""
        now = time.time()
        self.calls = [call_time for call_time in self.calls if now - call_time < self.time_window]
        
        if len(self.calls) >= self.max_calls:
            sleep_time = self.time_window - (now - self.calls[0])
            if sleep_time > 0:
                time.sleep(sleep_time)
        
        self.calls.append(now)

class OptimizedAPIClient:
    """ä¼˜åŒ–çš„APIå®¢æˆ·ç«¯"""
    def __init__(self, config: JQConfig):
        self.config = config
        self.rate_limiter = RateLimiter()
        jqdatasdk.auth(config.username, config.password)
    
    @lru_cache(maxsize=1000)
    def get_stock_price_cached(self, code: str, date: str) -> pd.DataFrame:
        """å¸¦ç¼“å­˜çš„è‚¡ç¥¨ä»·æ ¼è·å–"""
        self.rate_limiter.wait_if_needed()
        return jqdatasdk.get_price(code, start_date=date, end_date=date)
    
    def batch_get_prices(self, stock_codes: List[str], date: str, batch_size: int = 50) -> Dict[str, pd.DataFrame]:
        """æ‰¹é‡è·å–è‚¡ç¥¨ä»·æ ¼"""
        results = {}
        for i in range(0, len(stock_codes), batch_size):
            batch = stock_codes[i:i + batch_size]
            try:
                # ä½¿ç”¨JoinQuantçš„æ‰¹é‡API
                df = jqdatasdk.get_price(batch, start_date=date, end_date=date)
                for code in batch:
                    results[code] = df[df.index.get_level_values('code') == code]
            except Exception as e:
                print(f"æ‰¹é‡è·å–å¤±è´¥ï¼Œå›é€€åˆ°å•ä¸ªè·å–: {e}")
                for code in batch:
                    results[code] = self.get_stock_price_cached(code, date)
        return results
```

### 2. æ•°æ®å¤„ç†ä¼˜åŒ–

**ä¼˜åŒ–å»ºè®®**:

```python
# core/data_processor.py
import pandas as pd
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import Callable, List

class DataProcessor:
    """æ•°æ®å¤„ç†å™¨"""
    
    @staticmethod
    def parallel_process(
        items: List, 
        process_func: Callable, 
        max_workers: int = 4
    ) -> List:
        """å¹¶è¡Œå¤„ç†æ•°æ®"""
        results = []
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            future_to_item = {
                executor.submit(process_func, item): item 
                for item in items
            }
            
            for future in as_completed(future_to_item):
                try:
                    result = future.result()
                    results.append(result)
                except Exception as e:
                    item = future_to_item[future]
                    print(f"å¤„ç† {item} æ—¶å‡ºé”™: {e}")
        
        return results
    
    @staticmethod
    def optimize_dataframe(df: pd.DataFrame) -> pd.DataFrame:
        """ä¼˜åŒ–DataFrameå†…å­˜ä½¿ç”¨"""
        # ä¼˜åŒ–æ•°å€¼ç±»å‹
        for col in df.select_dtypes(include=['int64']).columns:
            df[col] = pd.to_numeric(df[col], downcast='integer')
        
        for col in df.select_dtypes(include=['float64']).columns:
            df[col] = pd.to_numeric(df[col], downcast='float')
        
        # ä¼˜åŒ–å­—ç¬¦ä¸²ç±»å‹
        for col in df.select_dtypes(include=['object']).columns:
            if df[col].nunique() / len(df) < 0.5:  # å¦‚æœé‡å¤å€¼è¾ƒå¤š
                df[col] = df[col].astype('category')
        
        return df
```

---

## ğŸ—ï¸ æ¶æ„ä¼˜åŒ–

### 1. æ¨¡å—åŒ–é‡æ„

**å»ºè®®çš„æ–°æ¶æ„**:

```
JQ/
â”œâ”€â”€ config/                   # é…ç½®ç®¡ç†
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ settings.py          # é…ç½®ç±»
â”‚   â””â”€â”€ environments.py       # ç¯å¢ƒé…ç½®
â”œâ”€â”€ core/                     # æ ¸å¿ƒåŠŸèƒ½
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ api_client.py        # APIå®¢æˆ·ç«¯
â”‚   â”œâ”€â”€ data_processor.py    # æ•°æ®å¤„ç†å™¨
â”‚   â”œâ”€â”€ storage.py           # å­˜å‚¨ç®¡ç†
â”‚   â””â”€â”€ cache.py             # ç¼“å­˜ç®¡ç†
â”œâ”€â”€ models/                   # æ•°æ®æ¨¡å‹
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ stock.py             # è‚¡ç¥¨æ¨¡å‹
â”‚   â””â”€â”€ financial.py         # è´¢åŠ¡æ¨¡å‹
â”œâ”€â”€ services/                 # ä¸šåŠ¡æœåŠ¡
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ stock_service.py     # è‚¡ç¥¨æœåŠ¡
â”‚   â”œâ”€â”€ financial_service.py # è´¢åŠ¡æœåŠ¡
â”‚   â””â”€â”€ market_service.py    # å¸‚åœºæœåŠ¡
â”œâ”€â”€ utils/                    # å·¥å…·å‡½æ•°
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ date_utils.py        # æ—¥æœŸå·¥å…·
â”‚   â”œâ”€â”€ validation.py        # æ•°æ®éªŒè¯
â”‚   â””â”€â”€ decorators.py        # è£…é¥°å™¨
â”œâ”€â”€ data/                     # æ•°æ®ç›®å½•
â”œâ”€â”€ tests/                    # æµ‹è¯•ä»£ç 
â””â”€â”€ scripts/                  # è„šæœ¬æ–‡ä»¶
```

### 2. æœåŠ¡å±‚è®¾è®¡

**ä¼˜åŒ–å»ºè®®**:

```python
# services/stock_service.py
from typing import List, Optional
import pandas as pd
from core.api_client import OptimizedAPIClient
from core.storage import DataStorage
from models.stock import StockPrice

class StockService:
    """è‚¡ç¥¨æ•°æ®æœåŠ¡"""
    
    def __init__(self, api_client: OptimizedAPIClient, storage: DataStorage):
        self.api_client = api_client
        self.storage = storage
    
    def get_daily_prices(
        self, 
        stock_codes: List[str], 
        date: str,
        force_update: bool = False
    ) -> pd.DataFrame:
        """è·å–æ—¥çº¿ä»·æ ¼æ•°æ®"""
        file_path = f"stock_price/{date}.csv"
        
        # æ£€æŸ¥æœ¬åœ°æ•°æ®
        if not force_update and self.storage.exists(file_path):
            return self.storage.read_csv(file_path)
        
        # ä»APIè·å–
        data = self.api_client.batch_get_prices(stock_codes, date)
        
        # åˆå¹¶æ•°æ®
        all_data = []
        for code, df in data.items():
            df['code'] = code
            all_data.append(df)
        
        result = pd.concat(all_data, ignore_index=True)
        
        # ä¿å­˜æ•°æ®
        self.storage.write_csv(file_path, result)
        
        return result
    
    def get_price_series(
        self, 
        code: str, 
        start_date: str, 
        end_date: str
    ) -> pd.DataFrame:
        """è·å–ä»·æ ¼æ—¶é—´åºåˆ—"""
        # å®ç°é€»è¾‘...
        pass
```

---

## ğŸ’¾ æ•°æ®ç®¡ç†ä¼˜åŒ–

### 1. å­˜å‚¨ç®¡ç†å™¨

**ä¼˜åŒ–å»ºè®®**:

```python
# core/storage.py
import os
import pandas as pd
from typing import Optional, List
from pathlib import Path
import shutil
import gzip
import json

class DataStorage:
    """æ•°æ®å­˜å‚¨ç®¡ç†å™¨"""
    
    def __init__(self, base_path: str = 'Database', compression: bool = True):
        self.base_path = Path(base_path)
        self.compression = compression
        self.base_path.mkdir(exist_ok=True)
    
    def write_csv(self, file_path: str, data: pd.DataFrame, **kwargs):
        """å†™å…¥CSVæ–‡ä»¶"""
        full_path = self.base_path / file_path
        full_path.parent.mkdir(parents=True, exist_ok=True)
        
        # é»˜è®¤å‚æ•°
        default_kwargs = {
            'index': False,
            'encoding': 'utf-8-sig'
        }
        default_kwargs.update(kwargs)
        
        if self.compression and len(data) > 10000:  # å¤§æ–‡ä»¶å‹ç¼©
            full_path_gz = full_path.with_suffix('.csv.gz')
            data.to_csv(full_path_gz, compression='gzip', **default_kwargs)
        else:
            data.to_csv(full_path, **default_kwargs)
    
    def read_csv(self, file_path: str, **kwargs) -> pd.DataFrame:
        """è¯»å–CSVæ–‡ä»¶"""
        full_path = self.base_path / file_path
        
        # æ£€æŸ¥å‹ç¼©æ–‡ä»¶
        full_path_gz = full_path.with_suffix('.csv.gz')
        if full_path_gz.exists():
            return pd.read_csv(full_path_gz, compression='gzip', **kwargs)
        elif full_path.exists():
            return pd.read_csv(full_path, **kwargs)
        else:
            raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
    
    def backup_data(self, source_dir: str, backup_name: Optional[str] = None):
        """å¤‡ä»½æ•°æ®"""
        if backup_name is None:
            backup_name = f"backup_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}"
        
        source_path = self.base_path / source_dir
        backup_path = self.base_path / 'backup' / backup_name
        
        if source_path.exists():
            shutil.copytree(source_path, backup_path)
            print(f"æ•°æ®å·²å¤‡ä»½è‡³: {backup_path}")
```

### 2. ç¼“å­˜ç®¡ç†

**ä¼˜åŒ–å»ºè®®**:

```python
# core/cache.py
import pickle
import hashlib
from pathlib import Path
from typing import Any, Optional
from datetime import datetime, timedelta

class DataCache:
    """æ•°æ®ç¼“å­˜ç®¡ç†å™¨"""
    
    def __init__(self, cache_dir: str = 'cache', default_ttl: int = 3600):
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(exist_ok=True)
        self.default_ttl = default_ttl
    
    def _get_cache_key(self, key: str) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        return hashlib.md5(key.encode()).hexdigest()
    
    def _get_cache_path(self, cache_key: str) -> Path:
        """è·å–ç¼“å­˜æ–‡ä»¶è·¯å¾„"""
        return self.cache_dir / f"{cache_key}.pkl"
    
    def get(self, key: str) -> Optional[Any]:
        """è·å–ç¼“å­˜æ•°æ®"""
        cache_key = self._get_cache_key(key)
        cache_path = self._get_cache_path(cache_key)
        
        if not cache_path.exists():
            return None
        
        # æ£€æŸ¥æ˜¯å¦è¿‡æœŸ
        metadata_path = cache_path.with_suffix('.meta')
        if metadata_path.exists():
            with open(metadata_path, 'r') as f:
                metadata = json.load(f)
                created_at = datetime.fromisoformat(metadata['created_at'])
                if datetime.now() - created_at > timedelta(seconds=metadata['ttl']):
                    cache_path.unlink(missing_ok=True)
                    metadata_path.unlink(missing_ok=True)
                    return None
        
        try:
            with open(cache_path, 'rb') as f:
                return pickle.load(f)
        except Exception:
            return None
    
    def set(self, key: str, value: Any, ttl: Optional[int] = None):
        """è®¾ç½®ç¼“å­˜æ•°æ®"""
        cache_key = self._get_cache_key(key)
        cache_path = self._get_cache_path(cache_key)
        metadata_path = cache_path.with_suffix('.meta')
        
        ttl = ttl or self.default_ttl
        
        try:
            with open(cache_path, 'wb') as f:
                pickle.dump(value, f)
            
            metadata = {
                'created_at': datetime.now().isoformat(),
                'ttl': ttl,
                'key': key
            }
            
            with open(metadata_path, 'w') as f:
                json.dump(metadata, f)
        except Exception as e:
            print(f"ç¼“å­˜å†™å…¥å¤±è´¥: {e}")
```

---

## ğŸ” æ•°æ®è´¨é‡ä¼˜åŒ–

### 1. æ•°æ®éªŒè¯å™¨

**ä¼˜åŒ–å»ºè®®**:

```python
# utils/validation.py
import pandas as pd
from typing import List, Dict, Any, Optional
from datetime import datetime

class DataValidator:
    """æ•°æ®éªŒè¯å™¨"""
    
    @staticmethod
    def validate_stock_price(df: pd.DataFrame) -> Dict[str, Any]:
        """éªŒè¯è‚¡ç¥¨ä»·æ ¼æ•°æ®"""
        issues = []
        
        # æ£€æŸ¥å¿…è¦å­—æ®µ
        required_columns = ['code', 'date', 'open', 'high', 'low', 'close', 'volume']
        missing_columns = [col for col in required_columns if col not in df.columns]
        if missing_columns:
            issues.append(f"ç¼ºå°‘å¿…è¦å­—æ®µ: {missing_columns}")
        
        # æ£€æŸ¥æ•°æ®ç±»å‹
        numeric_columns = ['open', 'high', 'low', 'close', 'volume']
        for col in numeric_columns:
            if col in df.columns and not pd.api.types.is_numeric_dtype(df[col]):
                issues.append(f"å­—æ®µ {col} åº”ä¸ºæ•°å€¼ç±»å‹")
        
        # æ£€æŸ¥ä»·æ ¼é€»è¾‘
        if all(col in df.columns for col in ['open', 'high', 'low', 'close']):
            invalid_prices = df[
                (df['high'] < df['low']) |
                (df['high'] < df['open']) |
                (df['high'] < df['close']) |
                (df['low'] > df['open']) |
                (df['low'] > df['close'])
            ]
            if not invalid_prices.empty:
                issues.append(f"å‘ç° {len(invalid_prices)} æ¡ä»·æ ¼é€»è¾‘é”™è¯¯è®°å½•")
        
        # æ£€æŸ¥è´Ÿå€¼
        if 'volume' in df.columns:
            negative_volume = df[df['volume'] < 0]
            if not negative_volume.empty:
                issues.append(f"å‘ç° {len(negative_volume)} æ¡è´Ÿæˆäº¤é‡è®°å½•")
        
        return {
            'is_valid': len(issues) == 0,
            'issues': issues,
            'total_records': len(df),
            'valid_records': len(df) - len(invalid_prices) if 'invalid_prices' in locals() else len(df)
        }
    
    @staticmethod
    def clean_data(df: pd.DataFrame, rules: Dict[str, Any]) -> pd.DataFrame:
        """æ ¹æ®è§„åˆ™æ¸…ç†æ•°æ®"""
        cleaned_df = df.copy()
        
        # å»é™¤é‡å¤è®°å½•
        if rules.get('remove_duplicates', True):
            cleaned_df = cleaned_df.drop_duplicates()
        
        # å¤„ç†ç¼ºå¤±å€¼
        if 'fill_na' in rules:
            cleaned_df = cleaned_df.fillna(rules['fill_na'])
        
        # ç§»é™¤å¼‚å¸¸å€¼
        if 'remove_outliers' in rules:
            for col, method in rules['remove_outliers'].items():
                if col in cleaned_df.columns:
                    if method == 'iqr':
                        Q1 = cleaned_df[col].quantile(0.25)
                        Q3 = cleaned_df[col].quantile(0.75)
                        IQR = Q3 - Q1
                        lower_bound = Q1 - 1.5 * IQR
                        upper_bound = Q3 + 1.5 * IQR
                        cleaned_df = cleaned_df[
                            (cleaned_df[col] >= lower_bound) &
                            (cleaned_df[col] <= upper_bound)
                        ]
        
        return cleaned_df
```

---

## ğŸ“Š ç›‘æ§å’Œæ—¥å¿—ä¼˜åŒ–

### 1. æ—¥å¿—ç®¡ç†

**ä¼˜åŒ–å»ºè®®**:

```python
# utils/logger.py
import logging
import sys
from pathlib import Path
from datetime import datetime
from typing import Optional

class Logger:
    """æ—¥å¿—ç®¡ç†å™¨"""
    
    def __init__(
        self, 
        name: str, 
        log_dir: str = 'logs',
        level: int = logging.INFO
    ):
        self.name = name
        self.log_dir = Path(log_dir)
        self.log_dir.mkdir(exist_ok=True)
        
        self.logger = logging.getLogger(name)
        self.logger.setLevel(level)
        
        # é¿å…é‡å¤æ·»åŠ å¤„ç†å™¨
        if not self.logger.handlers:
            self._setup_handlers()
    
    def _setup_handlers(self):
        """è®¾ç½®æ—¥å¿—å¤„ç†å™¨"""
        # æ§åˆ¶å°å¤„ç†å™¨
        console_handler = logging.StreamHandler(sys.stdout)
        console_formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        console_handler.setFormatter(console_formatter)
        self.logger.addHandler(console_handler)
        
        # æ–‡ä»¶å¤„ç†å™¨
        log_file = self.log_dir / f"{self.name}_{datetime.now().strftime('%Y%m%d')}.log"
        file_handler = logging.FileHandler(log_file, encoding='utf-8')
        file_formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(funcName)s:%(lineno)d - %(message)s'
        )
        file_handler.setFormatter(file_formatter)
        self.logger.addHandler(file_handler)
    
    def info(self, message: str):
        self.logger.info(message)
    
    def error(self, message: str):
        self.logger.error(message)
    
    def warning(self, message: str):
        self.logger.warning(message)
    
    def debug(self, message: str):
        self.logger.debug(message)

# ä½¿ç”¨è£…é¥°å™¨è®°å½•å‡½æ•°æ‰§è¡Œæƒ…å†µ
def log_execution_time(logger: Logger):
    """è®°å½•å‡½æ•°æ‰§è¡Œæ—¶é—´çš„è£…é¥°å™¨"""
    def decorator(func):
        def wrapper(*args, **kwargs):
            start_time = datetime.now()
            logger.info(f"å¼€å§‹æ‰§è¡Œ {func.__name__}")
            
            try:
                result = func(*args, **kwargs)
                end_time = datetime.now()
                execution_time = (end_time - start_time).total_seconds()
                logger.info(f"{func.__name__} æ‰§è¡Œå®Œæˆï¼Œè€—æ—¶: {execution_time:.2f}ç§’")
                return result
            except Exception as e:
                end_time = datetime.now()
                execution_time = (end_time - start_time).total_seconds()
                logger.error(f"{func.__name__} æ‰§è¡Œå¤±è´¥ï¼Œè€—æ—¶: {execution_time:.2f}ç§’ï¼Œé”™è¯¯: {e}")
                raise
        return wrapper
    return decorator
```

---

## ğŸ§ª æµ‹è¯•ä¼˜åŒ–

### 1. å•å…ƒæµ‹è¯•æ¡†æ¶

**ä¼˜åŒ–å»ºè®®**:

```python
# tests/test_stock_service.py
import unittest
from unittest.mock import Mock, patch
import pandas as pd
from services.stock_service import StockService
from core.api_client import OptimizedAPIClient
from core.storage import DataStorage

class TestStockService(unittest.TestCase):
    """è‚¡ç¥¨æœåŠ¡æµ‹è¯•"""
    
    def setUp(self):
        """æµ‹è¯•å‰å‡†å¤‡"""
        self.mock_api_client = Mock(spec=OptimizedAPIClient)
        self.mock_storage = Mock(spec=DataStorage)
        self.stock_service = StockService(self.mock_api_client, self.mock_storage)
    
    def test_get_daily_prices_from_cache(self):
        """æµ‹è¯•ä»ç¼“å­˜è·å–æ•°æ®"""
        # å‡†å¤‡æµ‹è¯•æ•°æ®
        test_data = pd.DataFrame({
            'code': ['000001.XSHE', '000002.XSHE'],
            'close': [10.5, 15.3],
            'volume': [1000000, 800000]
        })
        
        self.mock_storage.exists.return_value = True
        self.mock_storage.read_csv.return_value = test_data
        
        # æ‰§è¡Œæµ‹è¯•
        result = self.stock_service.get_daily_prices(['000001.XSHE', '000002.XSHE'], '2025-08-27')
        
        # éªŒè¯ç»“æœ
        self.assertEqual(len(result), 2)
        self.mock_storage.read_csv.assert_called_once()
    
    def test_get_daily_prices_from_api(self):
        """æµ‹è¯•ä»APIè·å–æ•°æ®"""
        test_data = pd.DataFrame({
            'code': ['000001.XSHE'],
            'close': [10.5],
            'volume': [1000000]
        })
        
        self.mock_storage.exists.return_value = False
        self.mock_api_client.batch_get_prices.return_value = {
            '000001.XSHE': test_data
        }
        
        result = self.stock_service.get_daily_prices(['000001.XSHE'], '2025-08-27')
        
        self.assertEqual(len(result), 1)
        self.mock_storage.write_csv.assert_called_once()

if __name__ == '__main__':
    unittest.main()
```

---

## ğŸš€ éƒ¨ç½²å’Œè¿ç»´ä¼˜åŒ–

### 1. ä»»åŠ¡è°ƒåº¦

**ä¼˜åŒ–å»ºè®®**:

```python
# scripts/scheduler.py
import schedule
import time
from datetime import datetime
from services.stock_service import StockService
from utils.logger import Logger

class DataUpdateScheduler:
    """æ•°æ®æ›´æ–°è°ƒåº¦å™¨"""
    
    def __init__(self, stock_service: StockService):
        self.stock_service = stock_service
        self.logger = Logger("scheduler")
    
    def update_daily_data(self):
        """æ›´æ–°æ—¥åº¦æ•°æ®"""
        try:
            today = datetime.now().strftime('%Y-%m-%d')
            self.logger.info(f"å¼€å§‹æ›´æ–° {today} çš„æ•°æ®")
            
            # è·å–æ‰€æœ‰è‚¡ç¥¨åˆ—è¡¨
            stock_codes = self.stock_service.get_all_stock_codes(today)
            
            # æ›´æ–°ä»·æ ¼æ•°æ®
            self.stock_service.get_daily_prices(stock_codes, today, force_update=True)
            
            # æ›´æ–°ä¼°å€¼æ•°æ®
            self.stock_service.get_daily_valuation(stock_codes, today, force_update=True)
            
            self.logger.info(f"{today} æ•°æ®æ›´æ–°å®Œæˆ")
        except Exception as e:
            self.logger.error(f"æ•°æ®æ›´æ–°å¤±è´¥: {e}")
    
    def setup_schedule(self):
        """è®¾ç½®è°ƒåº¦ä»»åŠ¡"""
        # æ¯ä¸ªå·¥ä½œæ—¥æ”¶ç›˜åæ›´æ–°æ•°æ®
        schedule.every().monday.at "16:30".do(self.update_daily_data)
        schedule.every().tuesday.at "16:30".do(self.update_daily_data)
        schedule.every().wednesday.at "16:30".do(self.update_daily_data)
        schedule.every().thursday.at "16:30".do(self.update_daily_data)
        schedule.every().friday.at "16:30".do(self.update_daily_data)
        
        # æ¯å‘¨æ—¥å‡Œæ™¨è¿›è¡Œæ•°æ®å¤‡ä»½
        schedule.every().sunday.at "02:00".do(self.backup_data)
    
    def run(self):
        """è¿è¡Œè°ƒåº¦å™¨"""
        self.setup_schedule()
        self.logger.info("æ•°æ®æ›´æ–°è°ƒåº¦å™¨å·²å¯åŠ¨")
        
        while True:
            schedule.run_pending()
            time.sleep(60)  # æ¯åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡

if __name__ == '__main__':
    # åˆå§‹åŒ–æœåŠ¡
    stock_service = StockService(...)
    scheduler = DataUpdateScheduler(stock_service)
    scheduler.run()
```

---

## ğŸ“ˆ æ€§èƒ½ç›‘æ§

### 1. æ€§èƒ½æŒ‡æ ‡æ”¶é›†

**ä¼˜åŒ–å»ºè®®**:

```python
# utils/monitoring.py
import time
import psutil
import pandas as pd
from typing import Dict, Any
from datetime import datetime
from dataclasses import dataclass

@dataclass
class PerformanceMetrics:
    """æ€§èƒ½æŒ‡æ ‡"""
    function_name: str
    execution_time: float
    memory_usage: float
    cpu_usage: float
    api_calls: int
    records_processed: int
    timestamp: datetime

class PerformanceMonitor:
    """æ€§èƒ½ç›‘æ§å™¨"""
    
    def __init__(self):
        self.metrics = []
    
    def track_performance(self, func_name: str):
        """æ€§èƒ½è·Ÿè¸ªè£…é¥°å™¨"""
        def decorator(func):
            def wrapper(*args, **kwargs):
                # å¼€å§‹ç›‘æ§
                start_time = time.time()
                start_memory = psutil.Process().memory_info().rss / 1024 / 1024  # MB
                start_cpu = psutil.cpu_percent()
                
                try:
                    result = func(*args, **kwargs)
                    
                    # ç»“æŸç›‘æ§
                    end_time = time.time()
                    end_memory = psutil.Process().memory_info().rss / 1024 / 1024
                    end_cpu = psutil.cpu_percent()
                    
                    # è®°å½•æŒ‡æ ‡
                    metrics = PerformanceMetrics(
                        function_name=func_name,
                        execution_time=end_time - start_time,
                        memory_usage=end_memory - start_memory,
                        cpu_usage=end_cpu - start_cpu,
                        api_calls=getattr(result, 'api_calls', 0),
                        records_processed=len(result) if isinstance(result, pd.DataFrame) else 0,
                        timestamp=datetime.now()
                    )
                    
                    self.metrics.append(metrics)
                    return result
                    
                except Exception as e:
                    # è®°å½•å¤±è´¥æŒ‡æ ‡
                    end_time = time.time()
                    metrics = PerformanceMetrics(
                        function_name=func_name,
                        execution_time=end_time - start_time,
                        memory_usage=0,
                        cpu_usage=0,
                        api_calls=0,
                        records_processed=0,
                        timestamp=datetime.now()
                    )
                    self.metrics.append(metrics)
                    raise
                    
            return wrapper
        return decorator
    
    def get_performance_report(self) -> pd.DataFrame:
        """è·å–æ€§èƒ½æŠ¥å‘Š"""
        if not self.metrics:
            return pd.DataFrame()
        
        data = []
        for metric in self.metrics:
            data.append({
                'function_name': metric.function_name,
                'execution_time': metric.execution_time,
                'memory_usage': metric.memory_usage,
                'cpu_usage': metric.cpu_usage,
                'api_calls': metric.api_calls,
                'records_processed': metric.records_processed,
                'timestamp': metric.timestamp
            })
        
        return pd.DataFrame(data)
```

---

## ğŸ¯ ä¼˜åŒ–å®æ–½è·¯çº¿å›¾

### ç¬¬ä¸€é˜¶æ®µï¼ˆ1-2å‘¨ï¼‰ï¼šåŸºç¡€ä¼˜åŒ–
- [ ] ç»Ÿä¸€ä»£ç é£æ ¼å’Œå‘½åè§„èŒƒ
- [ ] æ·»åŠ ç±»å‹æ³¨è§£å’Œæ–‡æ¡£å­—ç¬¦ä¸²
- [ ] å»ºç«‹é…ç½®ç®¡ç†ç³»ç»Ÿ
- [ ] å®ç°åŸºç¡€æ—¥å¿—åŠŸèƒ½

### ç¬¬äºŒé˜¶æ®µï¼ˆ2-3å‘¨ï¼‰ï¼šæ€§èƒ½ä¼˜åŒ–
- [ ] å®ç°APIè°ƒç”¨é¢‘ç‡é™åˆ¶
- [ ] æ·»åŠ æ•°æ®ç¼“å­˜æœºåˆ¶
- [ ] ä¼˜åŒ–æ‰¹é‡å¤„ç†é€»è¾‘
- [ ] å®ç°å¹¶è¡Œå¤„ç†

### ç¬¬ä¸‰é˜¶æ®µï¼ˆ3-4å‘¨ï¼‰ï¼šæ¶æ„é‡æ„
- [ ] é‡æ„æ¨¡å—åŒ–æ¶æ„
- [ ] å®ç°æœåŠ¡å±‚è®¾è®¡
- [ ] å»ºç«‹æ•°æ®æ¨¡å‹ç±»
- [ ] ä¼˜åŒ–å­˜å‚¨ç®¡ç†

### ç¬¬å››é˜¶æ®µï¼ˆ4-5å‘¨ï¼‰ï¼šè´¨é‡æå‡
- [ ] æ·»åŠ æ•°æ®éªŒè¯åŠŸèƒ½
- [ ] å®ç°é”™è¯¯å¤„ç†æœºåˆ¶
- [ ] å»ºç«‹å•å…ƒæµ‹è¯•æ¡†æ¶
- [ ] æ·»åŠ æ€§èƒ½ç›‘æ§

### ç¬¬äº”é˜¶æ®µï¼ˆ5-6å‘¨ï¼‰ï¼šè¿ç»´ä¼˜åŒ–
- [ ] å®ç°ä»»åŠ¡è°ƒåº¦ç³»ç»Ÿ
- [ ] æ·»åŠ æ•°æ®å¤‡ä»½åŠŸèƒ½
- [ ] å»ºç«‹ç›‘æ§å‘Šè­¦æœºåˆ¶
- [ ] å®Œå–„æ–‡æ¡£å’Œéƒ¨ç½²æŒ‡å—

---

## ğŸ“Š é¢„æœŸæ”¶ç›Š

### æ€§èƒ½æå‡
- **APIè°ƒç”¨æ•ˆç‡**: å‡å°‘50-70%çš„APIè°ƒç”¨æ¬¡æ•°
- **æ•°æ®å¤„ç†é€Ÿåº¦**: æå‡3-5å€çš„æ•°æ®å¤„ç†é€Ÿåº¦
- **å†…å­˜ä½¿ç”¨**: é™ä½30-40%çš„å†…å­˜å ç”¨

### å¯ç»´æŠ¤æ€§æå‡
- **ä»£ç å¤ç”¨ç‡**: æå‡60%çš„ä»£ç å¤ç”¨ç‡
- **bugä¿®å¤æ—¶é—´**: å‡å°‘50%çš„bugä¿®å¤æ—¶é—´
- **æ–°åŠŸèƒ½å¼€å‘**: æå‡40%çš„æ–°åŠŸèƒ½å¼€å‘æ•ˆç‡

### ç³»ç»Ÿç¨³å®šæ€§
- **é”™è¯¯ç‡**: é™ä½80%çš„ç³»ç»Ÿé”™è¯¯ç‡
- **æ•°æ®è´¨é‡**: æå‡95%ä»¥ä¸Šçš„æ•°æ®å‡†ç¡®æ€§
- **ç³»ç»Ÿå¯ç”¨æ€§**: è¾¾åˆ°99.5%ä»¥ä¸Šçš„ç³»ç»Ÿå¯ç”¨æ€§

---

## ğŸ”š æ€»ç»“

æœ¬ä¼˜åŒ–å»ºè®®æ–‡æ¡£æä¾›äº†å…¨é¢çš„æ”¹è¿›æ–¹æ¡ˆï¼Œæ¶µç›–äº†ä»£ç è´¨é‡ã€æ€§èƒ½ä¼˜åŒ–ã€æ¶æ„è®¾è®¡ã€æ•°æ®ç®¡ç†ç­‰å¤šä¸ªç»´åº¦ã€‚é€šè¿‡åˆ†é˜¶æ®µå®æ–½è¿™äº›ä¼˜åŒ–å»ºè®®ï¼Œå¯ä»¥æ˜¾è‘—æå‡é¡¹ç›®çš„æ•´ä½“è´¨é‡å’Œè¿è¡Œæ•ˆç‡ï¼Œä¸ºåç»­çš„åŠŸèƒ½æ‰©å±•å’Œé•¿æœŸç»´æŠ¤å¥ å®šåšå®åŸºç¡€ã€‚

å»ºè®®é¡¹ç›®å›¢é˜Ÿæ ¹æ®å®é™…æƒ…å†µï¼Œä¼˜å…ˆå®æ–½å½±å“æœ€å¤§ã€å®æ–½éš¾åº¦è¾ƒä½çš„ä¼˜åŒ–é¡¹ç›®ï¼Œé€æ­¥æ¨è¿›æ•´ä½“ä¼˜åŒ–å·¥ä½œã€‚